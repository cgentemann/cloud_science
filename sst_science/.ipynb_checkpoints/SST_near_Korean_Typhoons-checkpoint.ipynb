{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST in Bavi, Mayas, Haishen\n",
    "  \n",
    "Authors\n",
    "* [Dr Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "* You are going to want numpy, pandas, matplotlib.pyplot, podaaacpy, and xarray\n",
    "* This cell also imports a parser so that a login file can be read to use podaacpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xhistogram\n",
    "!pip install eofs\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#This is for reading in and parsing the login file credentials\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "from lxml import objectify\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "#rcParams['figure.figsize'] = 5, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of SSTs during Typhoons in 2020 near Korea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Storm data from a thredds server\n",
    "- Note update - the thredds server has disappeared, so I have left the url in the code, but commented out and replaced it with a local copy of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/netcdf/IBTrACS.WP.v04r00.nc'\n",
    "url = './../data/IBTrACS.WP.v04r00.nc'\n",
    "\n",
    "ds_storm=xr.open_dataset(url)\n",
    "\n",
    "# the data isn't formatted very well & have to convert strings\n",
    "for var in ds_storm:\n",
    "    if not((ds_storm[var].dtype=='float32') or (ds_storm[var].dtype=='int16')):\n",
    "        ds_storm[var]=ds_storm[var].astype(str)\n",
    "\n",
    "#calculate max_wind for each storm, as an easy way to classify them\n",
    "ds_storm['max_wind']=ds_storm.usa_wind.max(dim='date_time',skipna=True)\n",
    "ds_storm['max_cat']=ds_storm.usa_sshs.max(dim='date_time',skipna=True)\n",
    "\n",
    "ds_storm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the storm data for 2020 storms we are interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_list,ilist = ['BAVI','MAYSAK','HAISHEN'],[]\n",
    "for name in storm_list:\n",
    "    iloc = np.where((ds_storm.name==name) & (ds_storm.time>np.datetime64('2020-07-01')))[0][0]\n",
    "    print(name,iloc)\n",
    "    ilist.append(iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the storm tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "for i in ilist:\n",
    "    ax.plot(ds_storm.lon[i,:],ds_storm.lat[i,:], transform=ccrs.PlateCarree())\n",
    "ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_storms = ds_storm.isel(storm=ilist)\n",
    "#subset_storms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where do big storms start out?  only look at 1980 to present (data goes back to 1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm['yr']=ds_storm.time[:,0].dt.year\n",
    "big = ds_storm.where((ds_storm.max_wind>80) & (ds_storm.yr>1980),drop=True)\n",
    "#big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the first point the typhoon is classified as a storm, color is max_wnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "for i in ilist:\n",
    "    plt.scatter(big.lon[:,0],big.lat[:,0],c=big.max_wind,transform=ccrs.PlateCarree())\n",
    "ax.set_extent([110, 200, 0, 50], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()\n",
    "plt.colorbar(label='max winds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big.time[:,0].dt.year,bins=np.arange(1980,2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm['yr']=ds_storm.time[:,0].dt.year\n",
    "ds_storm['mon']=ds_storm.time[:,0].dt.month\n",
    "big = ds_storm.where((ds_storm.max_cat>=3) & (ds_storm.yr>1982) & (ds_storm.mon==8),drop=True)\n",
    "plt.hist(big.time[:,0].dt.year,bins=np.arange(1982,2021)+.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# monthly frequency of storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins  = np.arange(0,13)+.5\n",
    "h = histogram(ds_storm.time[:,0].dt.month, bins=[bins])\n",
    "h.plot(marker='.')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate histogram of number of storms per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xhistogram.xarray import histogram\n",
    "bins = np.arange(1982,2022)+.5\n",
    "h = histogram(big.time[:,0].dt.year, bins=[bins])\n",
    "h.plot(marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in NOAA OI SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adir = 'F:/data/sat_data/sst/noaa_oisst/www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/'\n",
    "dir_pattern_zarr = adir + 'avhrr_zarr2/'\n",
    "ds_sst = xr.open_zarr(dir_pattern_zarr,consolidated=True)\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sst_climatology = ds_sst.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly = ds_sst.groupby('time.dayofyear')-sst_climatology\n",
    "\n",
    "sst_anomaly_monthly = sst_anomaly.resample(time='1MS').mean(keep_attrs=True,skipna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the SST data look like at a point near one of the storms origination point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomaly_monthly.sst.sel(lon=140,lat=20,method='nearest').plot()\n",
    "print('okay, that is noisy but looks like a jump up ~2000 and positive trend since 2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot monthly SST anomaly around where these storms started, zoom in on 2010 - present\n",
    "sst_anomaly_monthly.sst.sel(lon=140.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "sst_anomaly_monthly.sst.sel(lon=130.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "print('okay, definitiely getting warmer from 2015 onward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's just look at August SSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomaly_monthly.sst[11::12,:,:].sel(lon=140.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "sst_anomaly_monthly.sst[11::12,:,:].sel(lon=130.125,lat=20.125,time=slice('2010','2021')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the trend in August temperatures for this region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_max_north_area.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is the region where all 3 storms started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "dx=2\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(120,145),lat=slice(15,25)).mean({'lat','lon'})\n",
    "#ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(122-dx,145+dx),lat=slice(16-dx,23+dx)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make west pacific subset and then save only august"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = sst_anomaly_monthly.sel(lon=slice(80,175),lat=slice(0,45))\n",
    "aug = wp.sst[11::12,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot anomaly 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "aug[-1,:,:].plot(vmin=-2,vmax=2,cmap='RdBu_r',transform=ccrs.PlateCarree(),cbar_kwargs={'label': 'SST Anomaly (K)'})\n",
    "for i in ilist:\n",
    "    ax.plot(ds_storm.lon[i,:],ds_storm.lat[i,:], transform=ccrs.PlateCarree(),label=ds_storm.name[i].data,linewidth=3)\n",
    "ax.set_extent([100,175, 0, 45], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()\n",
    "ax.legend()\n",
    "r1,r2,r3,r4 = 120,147,15,25\n",
    "ax.plot([r1,r1],[r3,r4],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r2,r2],[r3,r4],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r1,r2],[r3,r3],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r1,r2],[r4,r4],'k', transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(ds_storm.lon[ilist,0].data),max(ds_storm.lon[ilist,0].data),min(ds_storm.lat[ilist,0].data),max(ds_storm.lat[ilist,0].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xarray as xr\n",
    "#from xmovie import Movie\n",
    "\n",
    "#mov = Movie(wp.sst[11::12,:,:],cmap='RdBu_r',vmin=-2,vmax=2)\n",
    "#mov.save('f:/data/sst_westpacB.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the historical temperatures where these storms formed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in ilist:\n",
    "    xlon = ds_storm.lon[i,0].data\n",
    "    xlat = ds_storm.lat[i,0].data\n",
    "    ts = wp.sel(lat=slice(xlat-5,xlat+15),lon=slice(xlon-15,xlon+5)).mean({'lat','lon'})\n",
    "    plt.plot(ts.time.dt.year[11::12],ts.sst[11::12],label=ds_storm.name[i].data)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in ilist:\n",
    "    xlon = ds_storm.lon[i,0].data\n",
    "    xlat = ds_storm.lat[i,0].data\n",
    "    ts = wp.sel(lat=slice(xlat-5,xlat+5),lon=slice(xlon-5,xlon+5)).mean({'lat','lon'})\n",
    "    plt.plot(ts.time.dt.year[11::12],ts.sst[11::12],label=ds_storm.name[i].data)\n",
    "plt.legend()\n",
    "h.plot(marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load SST monthly anomaly for august\n",
    "- this is a small enough dataset that to make everything faster we can just load into memory and avoid chuncking issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = sst_anomaly_monthly.anom[11::12,:,:].load()  #AUGUST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove mean and trend\n",
    "- detrend the data and put back into xr.DataArray & fill back in nan\n",
    "- sst2 = sst_debias - sst_slope.slope*sst_debias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_debias = sst - sst.mean({'time'})\n",
    "sst2 = signal.detrend(sst_debias.fillna(0),axis=0,type='linear')\n",
    "sst2 = xr.DataArray(sst2,dims=['time','lat','lon'],coords={'time':sst_debias.time,'lat':sst_debias.lat,'lon':sst_debias.lon})\n",
    "sst2 = sst2.where(~np.isnan(sst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = sst_debias-sst2 #cal difference between sst with bias removed and sst with trend removed\n",
    "((dif.sel(time='2010-08-01')-dif.sel(time='2000-08-01'))).plot(vmin=-1,vmax=1,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sst2.sel(lon=150,lat=40,method='nearest'),label='detrend')\n",
    "plt.plot(sst_debias.sel(lon=150,lat=40,method='nearest'),label='debias')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "# latitude weights are applied before the computation of EOFs.\n",
    "coslat = np.cos(np.deg2rad(sst2.coords['lat'].values))\n",
    "wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "solver = Eof(sst2, weights=wgts)\n",
    "\n",
    "# Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "# PC time series and the input SST anomalies at each grid point, and the\n",
    "# leading PC time series itself.\n",
    "eof1 = solver.eofsAsCorrelation(neofs=5)\n",
    "pc1 = solver.pcs(npcs=5, pcscaling=1)\n",
    "\n",
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[0].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF1 (ENSO - M1) expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 0].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC1 Time Series', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[1].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF2 expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 1].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC2 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[2].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF3 ENSO expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 2].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC3 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[3].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF4 expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 3].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC4 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data0 = solver.reconstructedField(0)\n",
    "reconstructed_data1 = solver.reconstructedField(1)\n",
    "reconstructed_data2 = solver.reconstructedField(2)\n",
    "reconstructed_data3 = solver.reconstructedField(3)\n",
    "reconstructed_data4 = solver.reconstructedField(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2,r3,r4 = 120,145,15,25\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "#ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b',label='data')\n",
    "ts0 = reconstructed_data0.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts1 = reconstructed_data1.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts2 = reconstructed_data2.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts3 = reconstructed_data3.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts4 = reconstructed_data4.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts_trend = dif.sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts0+ts_trend,linewidth=2,color='r',label='reconstructed0')\n",
    "plt.plot(ts.time,ts1+ts_trend,linewidth=2,color='m',label='reconstructed1')\n",
    "plt.plot(ts.time,ts2+ts_trend,linewidth=2,color='c',label='reconstructed2')\n",
    "plt.plot(ts.time,ts3+ts_trend,linewidth=2,color='g',label='reconstructed3')\n",
    "plt.plot(ts.time,ts4+ts_trend,linewidth=2,color='k',label='reconstructed4')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.legend()\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_reconstructed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts.time,ts0+ts_trend,linewidth=2,color='r',label='reconstructed1')\n",
    "plt.plot(ts.time,ts1+ts_trend,linewidth=2,color='m',label='reconstructed1')\n",
    "plt.plot(ts.time,ts2+ts_trend,linewidth=2,color='c',label='reconstructed1')\n",
    "plt.plot(ts.time,ts3+ts_trend,linewidth=2,color='g',label='reconstructed1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what does buoy data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='https://dods.ndbc.noaa.gov/thredds/dodsC/data/stdmet/52211/52211.ncml'\n",
    "ds_buoy = xr.open_dataset(fname).rename({'latitude':'lat','longitude':'lon'})\n",
    "ds_buoy['mon']=ds_buoy.time.dt.month\n",
    "#ds_buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_buoy_month = ds_buoy.resample(time='1MS').mean(keep_attrs=True,skipna=True)\n",
    "ds_buoy_month.sea_surface_temperature.plot()\n",
    "buoy_aug = ds_buoy_month.where(ds_buoy_month.mon==8,drop=True)\n",
    "buoy_aug.sea_surface_temperature.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy_clim = sst_climatology.sst.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "sst_anomaly_buoy = ds_buoy.sea_surface_temperature.groupby('time.dayofyear')-buoy_clim[:,0,0]\n",
    "sst_anomaly_buoy_monthly = sst_anomaly_buoy.resample(time='1MS').mean(keep_attrs=True,skipna=True)\n",
    "sst_anomaly_buoy_monthly[10::12].plot()\n",
    "plt.ylabel('SST anomaly (K)')\n",
    "print(sst_anomaly_buoy_monthly[10::12].load().data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot NOAA OI SST, reconstructed SST, and buoy SST all at buoy SST location\n",
    "- Just a note - if they don't agree there is something probably wrong because NOAA OI SSTs uses in situ data in their analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "plt.plot(ts.time,ts[:,0,0],linewidth=2,color='b',label='data')\n",
    "ts = reconstructed_data.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "ts_trend = dif.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "plt.plot(ts.time,ts[:,0,0]+ts_trend[:,0,0],linewidth=2,color='r',label='reconstructed')\n",
    "sst_anomaly_buoy_monthly[10::12].plot(color='k',marker='.',label='buoy')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.legend()\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_reconstructed_buoy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so what is going on? are all months warming like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imon in range(12):\n",
    "    imon2 = imon+4\n",
    "    sst = sst_anomaly_monthly.anom[imon2::12,:,:].load()  #monthly\n",
    "    sst_debias = sst - sst.mean({'time'})\n",
    "    sst2 = signal.detrend(sst_debias.fillna(0),axis=0,type='linear')\n",
    "    sst2 = xr.DataArray(sst2,dims=['time','lat','lon'],coords={'time':sst_debias.time,'lat':sst_debias.lat,'lon':sst_debias.lon})\n",
    "    sst2 = sst2.where(~np.isnan(sst))\n",
    "    dif = sst_debias-sst2 #cal difference between sst with bias removed and sst with trend removed\n",
    "    time0,time1='2010-'+str(imon+1).zfill(2)+'-01','2000-'+str(imon+1).zfill(2)+'-01'\n",
    "    ((dif.sel(time=time0)-dif.sel(time=time1))).plot(vmin=-1,vmax=1,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})\n",
    "    plt.savefig('F:/data/project_data/fluxsat/korea/sst_trend_mon'+str(imon+1)+'.png')\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when are SSTs warm enough for TCs?\n",
    "- TC require SST > 26.5  ref: https://journals.ametsoc.org/view/journals/clim/28/20/jcli-d-14-00637.1.xml\n",
    "- so write a function that calculates fraction of days in a month that SSTs >26.5\n",
    "- then once that is working, caluclate it for each year\n",
    "- then calculate if there is a trend in # days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fracdy(x):\n",
    "    return (((x.where(x>26.5)/x).sum({'time'}))/x.sizes['time'])\n",
    "def numdy(x):\n",
    "    return ((x.where(x>26.5)/x).sum({'time'}))\n",
    "frac = ds_sst.sst.groupby('time.month').map(fracdy)\n",
    "num = ds_sst.sst.groupby('time.month').map(numdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_yr = []\n",
    "for lyr in range(1982,2021):\n",
    "    tem = ds_sst.sst.sel(time=str(lyr))\n",
    "    frac = tem.groupby('time.month').map(fracdy)\n",
    "    frac_yr.append(frac)\n",
    "frac_yr = xr.concat(frac_yr, dim='time')\n",
    "frac_yr['time']=np.arange(1982,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2,r3,r4 = 120,145,15,25\n",
    "ts =frac_yr.isel(month=6).sel(lon=r2,lat=r4,method='nearest')\n",
    "f = (ts.sel(time=slice(2015,2020)).mean()-ts.sel(time=slice(1985,1990)).mean()).load()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts =frac_yr.isel(month=7)\n",
    "f = (ts.sel(time=slice(2015,2020)).mean('time')-ts.sel(time=slice(1985,1990)).mean('time')).load()\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "f.plot(vmin=-.75,vmax=.75,cmap='RdBu_r',transform=ccrs.PlateCarree())\n",
    "#ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.sel(lat=25,lon=145,method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_debias = ts - ts.mean({'time'})\n",
    "ts2 = signal.detrend(ts_debias.fillna(0),axis=0,type='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0,time1=2010,2000\n",
    "dif = ts_debias-ts2 #cal difference between sst with bias removed and sst with trend removed\n",
    "f = ((dif.sel(time=time0)-dif.sel(time=time1))) #.plot(vmin=-.25,vmax=.25,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "f.plot(vmin=-.25,vmax=.25,cmap='RdBu_r',transform=ccrs.PlateCarree())\n",
    "#ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
