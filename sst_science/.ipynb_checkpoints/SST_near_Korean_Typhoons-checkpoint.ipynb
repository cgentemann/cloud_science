{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST in Bavi, Mayas, Haishen\n",
    "  \n",
    "Authors\n",
    "* [Dr Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "\n",
    "\n",
    "## In Feb 2020 a GRL [paper](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020GL091430) came out connecting 3 closely occuring Typhoons near Korea to the California wildfires\n",
    "  \n",
    "\"Strong winds that accentuated a fire outbreak in the western United States in early September of 2020 resulted from an atmospheric wave train that spanned the Pacific Ocean. Days before the atmospheric waves developed in the United States, three western Pacific tropical cyclones (typhoons) underwent an extratropical transition over Korea within an unprecedentedly short span of 12 days. \"\n",
    "\n",
    "Figure 1 showed zonal winds averaged over a box located over NCal/Oregon. On 9/5 and again on 9/24 the zonal winds were strongly negative (Diablo winds) and both events had major fires.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "* You are going to want numpy, pandas, matplotlib.pyplot, podaaacpy, and xarray\n",
    "* This cell also imports a parser so that a login file can be read to use podaacpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xhistogram\n",
    "#!pip install eofs\n",
    "!pip install lxml\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#This is for reading in and parsing the login file credentials\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "from lxml import objectify\n",
    "from xhistogram.xarray import histogram\n",
    "from scipy import signal\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "#rcParams['figure.figsize'] = 5, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of SSTs during Typhoons in 2020 near Korea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Storm data from a thredds server\n",
    "- Note update - the thredds server has disappeared, so I have left the url in the code, but commented out and replaced it with a local copy of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/netcdf/IBTrACS.WP.v04r00.nc'\n",
    "url = './../data/IBTrACS.WP.v04r00.nc'\n",
    "\n",
    "ds_storm=xr.open_dataset(url)\n",
    "\n",
    "# the data isn't formatted very well & have to convert strings\n",
    "for var in ds_storm:\n",
    "    if not((ds_storm[var].dtype=='float32') or (ds_storm[var].dtype=='int16')):\n",
    "        ds_storm[var]=ds_storm[var].astype(str)\n",
    "\n",
    "#calculate max_wind for each storm, as an easy way to classify them\n",
    "ds_storm['max_wind']=ds_storm.usa_wind.max(dim='date_time',skipna=True)\n",
    "ds_storm['max_cat']=ds_storm.usa_sshs.max(dim='date_time',skipna=True)\n",
    "\n",
    "ds_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the storms and dates for west pacific year\n",
    "sub = ds_storm.where((ds_storm.basin=='WP') & (ds_storm.max_cat>=3) & (ds_storm.season==2017),drop=True)\n",
    "for i in range(len(sub.name)):\n",
    "    print(sub.time[i,0].data,sub.name[i,0].data,sub.max_cat[i,0].data)\n",
    "#list the storms and dates for west pacific year\n",
    "sub = ds_storm.where((ds_storm.basin=='WP') & (ds_storm.max_cat>=3) & (ds_storm.season==2018),drop=True)\n",
    "for i in range(len(sub.name)):\n",
    "    print(sub.time[i,0].data,sub.name[i,0].data,sub.max_cat[i,0].data)\n",
    "#list the storms and dates for west pacific year\n",
    "sub = ds_storm.where((ds_storm.basin=='WP') & (ds_storm.max_cat>=3) & (ds_storm.season==2019),drop=True)\n",
    "for i in range(len(sub.name)):\n",
    "    print(sub.time[i,0].data,sub.name[i,0].data,sub.max_cat[i,0].data)\n",
    "#list the storms and dates for west pacific year\n",
    "sub = ds_storm.where((ds_storm.basin=='WP') & (ds_storm.max_cat>=3) & (ds_storm.season==2020),drop=True)\n",
    "for i in range(len(sub.name)):\n",
    "    print(sub.time[i,0].data,sub.name[i,0].data,sub.max_cat[i,0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the storm data for 2020 storms we are interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_list,ilist = ['BAVI','MAYSAK','HAISHEN'],[]\n",
    "for name in storm_list:\n",
    "    iloc = np.where((ds_storm.name==name) & (ds_storm.time>np.datetime64('2020-07-01')))[0][0]\n",
    "    print(name,iloc)\n",
    "    ilist.append(iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the storm tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "for i in ilist:\n",
    "    ax.plot(ds_storm.lon[i,:],ds_storm.lat[i,:], transform=ccrs.PlateCarree())\n",
    "ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_storms = ds_storm.isel(storm=ilist)\n",
    "#subset_storms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where do big storms start out?  only look at 1980 to present (data goes back to 1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm['yr']=ds_storm.time[:,0].dt.year\n",
    "big = ds_storm.where((ds_storm.max_wind>80) & (ds_storm.yr>1980),drop=True)\n",
    "#big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the first point the typhoon is classified as a storm, color is max_wnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "for i in ilist:\n",
    "    plt.scatter(big.lon[:,0],big.lat[:,0],c=big.max_wind,transform=ccrs.PlateCarree())\n",
    "ax.set_extent([110, 200, 0, 50], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()\n",
    "plt.colorbar(label='max winds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big.time[:,0].dt.year,bins=np.arange(1980,2022))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm['yr']=ds_storm.time[:,0].dt.year\n",
    "ds_storm['mon']=ds_storm.time[:,0].dt.month\n",
    "big = ds_storm.where((ds_storm.max_cat>=3) & (ds_storm.yr>1982) & (ds_storm.mon==8),drop=True)\n",
    "plt.hist(big.time[:,0].dt.year,bins=np.arange(1982,2022))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# monthly frequency of storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins  = np.arange(0,13)\n",
    "h = histogram(ds_storm.time[:,0].dt.month, bins=[bins])\n",
    "h.plot(marker='.')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate histogram of number of storms per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(1982,2022)+.5\n",
    "h = histogram(big.time[:,0].dt.year, bins=[bins])\n",
    "h.plot(marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in NOAA OI SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adir = 'F:/data/sat_data/sst/noaa_oisst/www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/'\n",
    "dir_pattern_zarr = adir + 'avhrr_zarr2/'\n",
    "ds_sst = xr.open_zarr(dir_pattern_zarr,consolidated=True)\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sst_climatology = ds_sst.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly = ds_sst.groupby('time.dayofyear')-sst_climatology\n",
    "\n",
    "sst_anomaly_monthly = sst_anomaly.resample(time='1MS').mean(keep_attrs=True,skipna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the SST data look like at a point near one of the storms origination point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomaly_monthly.sst.sel(lon=140,lat=20,method='nearest').plot()\n",
    "print('okay, that is noisy but looks like a jump up ~2000 and positive trend since 2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot monthly SST anomaly around where these storms started, zoom in on 2010 - present\n",
    "sst_anomaly_monthly.sst.sel(lon=140.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "sst_anomaly_monthly.sst.sel(lon=130.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "print('okay, definitiely getting warmer from 2015 onward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's just look at August SSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomaly_monthly.sst[11::12,:,:].sel(lon=140.125,lat=20.125,time=slice('2010','2021')).plot()\n",
    "sst_anomaly_monthly.sst[11::12,:,:].sel(lon=130.125,lat=20.125,time=slice('2010','2021')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the trend in August temperatures for this region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_max_north_area.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is the region where all 3 storms started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "dx=2\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(120,145),lat=slice(15,25)).mean({'lat','lon'})\n",
    "#ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(122-dx,145+dx),lat=slice(16-dx,23+dx)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make west pacific subset and then save only august"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = sst_anomaly_monthly.sel(lon=slice(80,175),lat=slice(0,45))\n",
    "aug = wp.sst[11::12,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot anomaly 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "aug[-1,:,:].plot(vmin=-2,vmax=2,cmap='RdBu_r',transform=ccrs.PlateCarree(),cbar_kwargs={'label': 'SST Anomaly (K)'})\n",
    "for i in ilist:\n",
    "    ax.plot(ds_storm.lon[i,:],ds_storm.lat[i,:], transform=ccrs.PlateCarree(),label=ds_storm.name[i].data,linewidth=3)\n",
    "ax.set_extent([100,175, 0, 45], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()\n",
    "ax.legend()\n",
    "r1,r2,r3,r4 = 120,147,15,25\n",
    "ax.plot([r1,r1],[r3,r4],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r2,r2],[r3,r4],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r1,r2],[r3,r3],'k', transform=ccrs.PlateCarree())\n",
    "ax.plot([r1,r2],[r4,r4],'k', transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(ds_storm.lon[ilist,0].data),max(ds_storm.lon[ilist,0].data),min(ds_storm.lat[ilist,0].data),max(ds_storm.lat[ilist,0].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xarray as xr\n",
    "#from xmovie import Movie\n",
    "\n",
    "#mov = Movie(wp.sst[11::12,:,:],cmap='RdBu_r',vmin=-2,vmax=2)\n",
    "#mov.save('f:/data/sst_westpacB.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the historical temperatures where these storms formed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in ilist:\n",
    "    xlon = ds_storm.lon[i,0].data\n",
    "    xlat = ds_storm.lat[i,0].data\n",
    "    ts = wp.sel(lat=slice(xlat-5,xlat+15),lon=slice(xlon-15,xlon+5)).mean({'lat','lon'})\n",
    "    plt.plot(ts.time.dt.year[11::12],ts.sst[11::12],label=ds_storm.name[i].data)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "for i in ilist:\n",
    "    xlon = ds_storm.lon[i,0].data\n",
    "    xlat = ds_storm.lat[i,0].data\n",
    "    ts = wp.sel(lat=slice(xlat-5,xlat+5),lon=slice(xlon-5,xlon+5)).mean({'lat','lon'})\n",
    "    plt.plot(ts.time.dt.year[11::12],ts.sst[11::12],label=ds_storm.name[i].data)\n",
    "plt.legend()\n",
    "h.plot(marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load SST monthly anomaly for august\n",
    "- this is a small enough dataset that to make everything faster we can just load into memory and avoid chuncking issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = sst_anomaly_monthly.anom[11::12,:,:].load()  #AUGUST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove mean and trend\n",
    "- detrend the data and put back into xr.DataArray & fill back in nan\n",
    "- sst2 = sst_debias - sst_slope.slope*sst_debias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_debias = sst - sst.mean({'time'})\n",
    "sst2 = signal.detrend(sst_debias.fillna(0),axis=0,type='linear')\n",
    "sst2 = xr.DataArray(sst2,dims=['time','lat','lon'],coords={'time':sst_debias.time,'lat':sst_debias.lat,'lon':sst_debias.lon})\n",
    "sst2 = sst2.where(~np.isnan(sst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = sst_debias-sst2 #cal difference between sst with bias removed and sst with trend removed\n",
    "((dif.sel(time='2010-08-01')-dif.sel(time='2000-08-01'))).plot(vmin=-1,vmax=1,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sst2.sel(lon=150,lat=40,method='nearest'),label='detrend')\n",
    "plt.plot(sst_debias.sel(lon=150,lat=40,method='nearest'),label='debias')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "# latitude weights are applied before the computation of EOFs.\n",
    "coslat = np.cos(np.deg2rad(sst2.coords['lat'].values))\n",
    "wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "solver = Eof(sst2, weights=wgts)\n",
    "\n",
    "# Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "# PC time series and the input SST anomalies at each grid point, and the\n",
    "# leading PC time series itself.\n",
    "eof1 = solver.eofsAsCorrelation(neofs=5)\n",
    "pc1 = solver.pcs(npcs=5, pcscaling=1)\n",
    "\n",
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[0].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF1 (ENSO - M1) expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 0].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC1 Time Series', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[1].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF2 expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 1].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC2 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[2].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF3 ENSO expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 2].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC3 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=190))\n",
    "fill = eof1[3].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                             add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF4 expressed as correlation', fontsize=16)\n",
    "\n",
    "# Plot the leading PC time series.\n",
    "plt.figure()\n",
    "pc1[:, 3].plot(color='b', linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Normalized Units')\n",
    "ax.set_title('PC4 Time Series', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data0 = solver.reconstructedField(0)\n",
    "reconstructed_data1 = solver.reconstructedField(1)\n",
    "reconstructed_data2 = solver.reconstructedField(2)\n",
    "reconstructed_data3 = solver.reconstructedField(3)\n",
    "reconstructed_data4 = solver.reconstructedField(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2,r3,r4 = 120,145,15,25\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "#ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts,linewidth=2,color='b',label='data')\n",
    "ts0 = reconstructed_data0.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts1 = reconstructed_data1.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts2 = reconstructed_data2.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts3 = reconstructed_data3.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts4 = reconstructed_data4.sel(lon=slice(r1,r2),lat=slice(r3,r4)).mean({'lat','lon'})\n",
    "ts_trend = dif.sel(lon=slice(130,150),lat=slice(20,30)).mean({'lat','lon'})\n",
    "plt.plot(ts.time,ts0+ts_trend,linewidth=2,color='r',label='reconstructed0')\n",
    "plt.plot(ts.time,ts1+ts_trend,linewidth=2,color='m',label='reconstructed1')\n",
    "plt.plot(ts.time,ts2+ts_trend,linewidth=2,color='c',label='reconstructed2')\n",
    "plt.plot(ts.time,ts3+ts_trend,linewidth=2,color='g',label='reconstructed3')\n",
    "plt.plot(ts.time,ts4+ts_trend,linewidth=2,color='k',label='reconstructed4')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.legend()\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_reconstructed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts.time,ts0+ts_trend,linewidth=2,color='r',label='reconstructed1')\n",
    "plt.plot(ts.time,ts1+ts_trend,linewidth=2,color='m',label='reconstructed1')\n",
    "plt.plot(ts.time,ts2+ts_trend,linewidth=2,color='c',label='reconstructed1')\n",
    "plt.plot(ts.time,ts3+ts_trend,linewidth=2,color='g',label='reconstructed1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what does buoy data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='https://dods.ndbc.noaa.gov/thredds/dodsC/data/stdmet/52211/52211.ncml'\n",
    "ds_buoy = xr.open_dataset(fname).rename({'latitude':'lat','longitude':'lon'})\n",
    "ds_buoy['mon']=ds_buoy.time.dt.month\n",
    "#ds_buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_buoy_month = ds_buoy.resample(time='1MS').mean(keep_attrs=True,skipna=True)\n",
    "ds_buoy_month.sea_surface_temperature.plot()\n",
    "buoy_aug = ds_buoy_month.where(ds_buoy_month.mon==8,drop=True)\n",
    "buoy_aug.sea_surface_temperature.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy_clim = sst_climatology.sst.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "sst_anomaly_buoy = ds_buoy.sea_surface_temperature.groupby('time.dayofyear')-buoy_clim[:,0,0]\n",
    "sst_anomaly_buoy_monthly = sst_anomaly_buoy.resample(time='1MS').mean(keep_attrs=True,skipna=True)\n",
    "sst_anomaly_buoy_monthly[10::12].plot()\n",
    "plt.ylabel('SST anomaly (K)')\n",
    "#print(sst_anomaly_buoy_monthly[10::12].load().data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot NOAA OI SST, reconstructed SST, and buoy SST all at buoy SST location\n",
    "- Just a note - if they don't agree there is something probably wrong because NOAA OI SSTs uses in situ data in their analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ts = sst_anomaly_monthly.sst[11::12,:,:].sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "plt.plot(ts.time,ts[:,0,0],linewidth=2,color='b',label='data')\n",
    "ts = reconstructed_data4.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "ts_trend = dif.sel(lat=ds_buoy.lat,lon=ds_buoy.lon,method='nearest')\n",
    "plt.plot(ts.time,ts[:,0,0]+ts_trend[:,0,0],linewidth=2,color='r',label='reconstructed')\n",
    "sst_anomaly_buoy_monthly[10::12].plot(color='k',marker='.',label='buoy')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('SST Anomaly (K)')\n",
    "plt.legend()\n",
    "plt.savefig('F:/data/project_data/fluxsat/korea/aug_sst_reconstructed_buoy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so what is going on? are all months warming like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imon in range(12):\n",
    "    imon2 = imon+4\n",
    "    sst = sst_anomaly_monthly.anom[imon2::12,:,:].load()  #monthly\n",
    "    sst_debias = sst - sst.mean({'time'})\n",
    "    sst2 = signal.detrend(sst_debias.fillna(0),axis=0,type='linear')\n",
    "    sst2 = xr.DataArray(sst2,dims=['time','lat','lon'],coords={'time':sst_debias.time,'lat':sst_debias.lat,'lon':sst_debias.lon})\n",
    "    sst2 = sst2.where(~np.isnan(sst))\n",
    "    dif = sst_debias-sst2 #cal difference between sst with bias removed and sst with trend removed\n",
    "    time0,time1='2010-'+str(imon+1).zfill(2)+'-01','2000-'+str(imon+1).zfill(2)+'-01'\n",
    "    ((dif.sel(time=time0)-dif.sel(time=time1))).plot(vmin=-1,vmax=1,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})\n",
    "    plt.savefig('F:/data/project_data/fluxsat/korea/sst_trend_mon'+str(imon+1)+'.png')\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when are SSTs warm enough for TCs?\n",
    "- TC require SST > 26.5  ref: https://journals.ametsoc.org/view/journals/clim/28/20/jcli-d-14-00637.1.xml\n",
    "- so write a function that calculates fraction of days in a month that SSTs >26.5\n",
    "- then once that is working, caluclate it for each year\n",
    "- then calculate if there is a trend in # days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fracdy(x):\n",
    "    return (((x.where(x>26.5)/x).sum({'time'}))/x.sizes['time'])\n",
    "def numdy(x):\n",
    "    return ((x.where(x>26.5)/x).sum({'time'}))\n",
    "frac = ds_sst.sst.groupby('time.month').map(fracdy)\n",
    "num = ds_sst.sst.groupby('time.month').map(numdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_yr = []\n",
    "for lyr in range(1982,2021):\n",
    "    tem = ds_sst.sst.sel(time=str(lyr))\n",
    "    frac = tem.groupby('time.month').map(fracdy)\n",
    "    frac_yr.append(frac)\n",
    "frac_yr = xr.concat(frac_yr, dim='time')\n",
    "frac_yr['time']=np.arange(1982,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2,r3,r4 = 120,145,15,25\n",
    "ts =frac_yr.isel(month=6).sel(lon=r2,lat=r4,method='nearest')\n",
    "f = (ts.sel(time=slice(2015,2020)).mean()-ts.sel(time=slice(1985,1990)).mean()).load()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts =frac_yr.isel(month=7)\n",
    "f = (ts.sel(time=slice(2015,2020)).mean('time')-ts.sel(time=slice(1985,1990)).mean('time')).load()\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "f.plot(vmin=-.75,vmax=.75,cmap='RdBu_r',transform=ccrs.PlateCarree())\n",
    "#ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.sel(lat=25,lon=145,method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_debias = ts - ts.mean({'time'})\n",
    "ts2 = signal.detrend(ts_debias.fillna(0),axis=0,type='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0,time1=2010,2000\n",
    "dif = ts_debias-ts2 #cal difference between sst with bias removed and sst with trend removed\n",
    "f = ((dif.sel(time=time0)-dif.sel(time=time1))) #.plot(vmin=-.25,vmax=.25,cmap='RdBu_r',cbar_kwargs={'label': 'SST trend (K/decade)'})\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "f.plot(vmin=-.25,vmax=.25,cmap='RdBu_r',transform=ccrs.PlateCarree())\n",
    "#ax.set_extent([110, 150, 10, 60], crs=ccrs.PlateCarree())\n",
    "ax.coastlines('50m')\n",
    "ax.stock_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = ds_storm.where((ds_storm.max_wind>50) & (ds_storm.yr>1980))\n",
    "plt.scatter(sub.lon[:,0],sub.lat[:,0],c=sub.yr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=[]\n",
    "for iyr in range(1980,2021):\n",
    "    sub = ds_storm.where((ds_storm.max_wind>50) & (ds_storm.yr==1980),drop=True)\n",
    "    h = plt.hist(sub.lat[:,0],bins=np.arange(0,40,2))\n",
    "    h1 = xr.DataArray(h[0]/sum(h[0]),coords={'lat':h[1][:-1]},dims=('lat'))\n",
    "    hh.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = xr.concat(hh,dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
