{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Example: Ocean Data from NASA JPL PO.DAAC \n",
    "###  Ocean area with temperature above a given threshold\n",
    "\n",
    "In this chapter we exemplify the use of Sea Surface Temperature (SST) data in the cloud.\n",
    "\n",
    "- Read JPL PO.DAAC NetCDF files directly\n",
    "\n",
    "This example analyze a time series from an area of the ocean or a point. If an area, averages SST values. Then it analyze the time series to assess when SST is above a given threshold. This could be used to study marine heatwaves, or use a threshold relevant for a marine species of interest.\n",
    "\n",
    "# Example: Ocean Data from NASA JPL PO.DAAC\n",
    "###  Ocean area with temperature above a given threshold\n",
    "\n",
    "Here we exemplify the use of Sea Surface Temperature (SST) data in the cloud. \n",
    "\n",
    "This example analyze a time series from an average area of the ocean or a point. Then it analyze the time series to assess when SST is above a given threshold. This could be used to study marine heatwaves, or use a threshold relevant for a marine species of interest.\n",
    "\n",
    "Authors:\n",
    "- [Marisol Garcia-Reyes](https://github.com/marisolgr)\n",
    "- [Chelle Gentemann](https://github.com/cgentemann)\n",
    "\n",
    "Credit:\n",
    "- Funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "import hvplot.xarray\n",
    "import warnings\n",
    "\n",
    "# these libraries help reading cloud data\n",
    "import fsspec \n",
    "import s3fs\n",
    "import requests\n",
    "\n",
    "warnings.simplefilter(\"ignore\")  # filter some warning messages\n",
    "xr.set_options(display_style=\"html\",keep_attrs=True)  # display dataset nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "# Select either a range of lat/lon or a point. \n",
    "latr = [19, 20] # make sure lat1 > lat2 since no test is done below to simplify the code\n",
    "lonr = [-158, -157] # lon1 > lon2, range -180:180. resolution daily 1km!\n",
    "# time range. data range available: 2002-06-01 to 2020-01-20. [start with a short period]\n",
    "dater = ['2012-01-01','2019-12-31'] # dates on the format 'YYYY-MM-DD' as string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## We are going to use the Multi-Scale Ultra High Resolution (MUR) Sea Surface Temperature (SST) data set\n",
    "### Stored the NASA PO.DAAC Amazon (AWS) Cloud. For more info and links to the data detail and examples, [here](https://podaac.jpl.nasa.gov/dataset/MUR-JPL-L4-GLOB-v4.1).\n",
    "\n",
    "This dataset is stored in netCDF format, which can be very slow to access over S3 glob storage using xr.open_mfdataset because it has to collect the metadata from each file. We have created a reference file using the Kerchunk library and are accessing the entire 18-year 1-km dataset using the Zarr library. So, even though the files are netCDF, we are accessing them using the Zarr library and gaining two key advantages \n",
    "- access entire dataset in ~2 min versus 50 min for netcdf\n",
    "- data reads are concurrent & faster using zarr library.\n",
    "\n",
    "To access the PO.DAAC cloud MUR SSTs:\n",
    "- input your earthdata login and password  (if you don't have a login then register [here](https://urs.earthdata.nasa.gov/))\n",
    "- set up credentials\n",
    "- access the Kerchunk consolidated metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthdata import Auth \n",
    "auth = Auth().login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join\n",
    "\n",
    "def begin_s3_direct_access():\n",
    "    url = \"https://archive.podaac.earthdata.nasa.gov/s3credentials\"\n",
    "    response = requests.get(url).json()\n",
    "    return s3fs.S3FileSystem(\n",
    "        key=response[\"accessKeyId\"],\n",
    "        secret=response[\"secretAccessKey\"],\n",
    "        token=response[\"sessionToken\"],\n",
    "        client_kwargs={\"region_name\": \"us-west-2\"},\n",
    "    )\n",
    "\n",
    "start_year = int(dater[0][0:4])\n",
    "end_year = int(dater[1][0:4])\n",
    "print(start_year, end_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to break it down month by month - stops after 24 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fs = begin_s3_direct_access()\n",
    "ds_sst=[]\n",
    "for lyr in range(start_year,end_year):\n",
    "    for imon in range(1,13):\n",
    "        fstr = str(lyr)+str(imon).zfill(2)+'*.nc'\n",
    "        files = fs.glob(join(\"podaac-ops-cumulus-protected/\", \"MUR-JPL-L4-GLOB-v4.1\", fstr))\n",
    "        # Iterate through remote_files to create a fileset\n",
    "        fileset = [fs.open(file) for file in files]\n",
    "        tem = xr.open_mfdataset(fileset,combine=\"by_coords\")\n",
    "        ds_sst.append(tem)\n",
    "        print(lyr,imon,len(ds_sst))\n",
    "ds_sst = xr.concat(ds_sst,dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to do year by year, stops after 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fs = begin_s3_direct_access()\n",
    "ds_sst=[]\n",
    "for lyr in range(start_year,end_year):\n",
    "    fstr = str(lyr)+'*.nc'\n",
    "    files = fs.glob(join(\"podaac-ops-cumulus-protected/\", \"MUR-JPL-L4-GLOB-v4.1\", fstr))\n",
    "    tem = xr.open_mfdataset(\n",
    "        paths=[fs.open(f) for f in files],\n",
    "        combine=\"by_coords\",\n",
    "    )\n",
    "    tem.close()\n",
    "    ds_sst.append(tem)\n",
    "    print(lyr,len(ds_sst))\n",
    "ds_sst = xr.concat(ds_sst,dim='time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs but after 12 hours still running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try step_1 way\n",
    "#%%time\n",
    "fs = begin_s3_direct_access()\n",
    "flist = []\n",
    "for lyr in range(start_year,end_year+1):\n",
    "    for imon in range(1,13):\n",
    "        fstr = str(lyr)+str(imon).zfill(2)+'*.nc'\n",
    "        files = fs.glob(join(\"podaac-ops-cumulus-protected/\", \"MUR-JPL-L4-GLOB-v4.1\", fstr))\n",
    "        for file in files:\n",
    "            flist.append(file)\n",
    "print('total number of individual netcdf files:',len(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "urls = [\"s3://\" + f for f in flist]\n",
    "so = dict(mode='rb', anon=True, default_fill_cache=False, default_cache_type='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(u,ds_sst):\n",
    "    with fs.open(u, **so) as infile:\n",
    "        tem = xr.open_dataset(infile)\n",
    "    ds_sst.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask\n",
    "ds_sst=[]\n",
    "_ = dask.compute(*[dask.delayed(get_data)(u,ds_sst) for u in urls], retries=10);\n",
    "ds_sst = xr.concat(ds_sst,dim='time')\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we know what the file contains, we select our data (region and time), operate on it if needed (if a region, average), and download only that data \n",
    "It takes a while, given the high resolution of the data. So, be patient.... and if you're only testing, might want to choose a small region and a short time period first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds_sst['analysed_sst'].sel(time = slice(dater[0],dater[1]),\n",
    "                                        lat  = slice(latr[0], latr[1]), \n",
    "                                        lon  = slice(lonr[0], lonr[1])\n",
    "                                       ).mean(dim={'lat','lon'}, \n",
    "                                              skipna=True) # skip 'not a number' values and keep attributes\n",
    "sst = sst-273.15 # transform Kelving to degrees Celsius\n",
    "sst.attrs['units']='deg C' #update units in metadata\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Let's plot the data using two different libraries.\n",
    "#### - `matplotlib` that we already learn. It makes static and very nice figures that can be customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - `hovplot` is a more interactive library for web display. it provides you with the data details when you hover your cursor over the figure. Very nice for inspecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Now, let's analyze our data.\n",
    "#### First, the a basic climatology and anomalies, and plotting using `hovplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the climatology\n",
    "sst_climatology = sst.groupby('time.dayofyear').mean('time',skipna=False) # Group by day, all years. skipna ignore missing values (NaN=Not a Number)\n",
    "sst_climstd = sst.groupby('time.dayofyear').std('time',skipna=False) # Calculate standard deviation. \n",
    "\n",
    "ds = xr.Dataset({'clim':sst_climatology,'+Std':sst_climatology+sst_climstd,'-Std':sst_climatology-sst_climstd})\n",
    "ds.hvplot(color=['k','grey','grey'], grid=True, title='SST Climatology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the anomalies\n",
    "sst_anomaly = sst.groupby('time.dayofyear')-sst_climatology \n",
    "sst_anomaly_monthly = sst_anomaly.resample(time='1MS', loffset='15D').mean(skipna=False) # calculate monthly anomalies/smoothing\n",
    "\n",
    "sst_anomaly.hvplot.area(x='time',grid=True, title='SST Anomalies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## We analyze the data further by choosing a threshold.\n",
    "\n",
    "- One way is to set a threshold that has some relevance.  For example, a thermal threshold for a marine species we are studying. \n",
    "\n",
    "- Another way is choosing the maximum value in the climatology (mean value + 1 standard deviation), which we can calculate or read by hovering our cursor over the climatology plot above.\n",
    "\n",
    "### Once the threshold is choosen, we identify when SST is over that threshold, and count how many days that occurred each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we define a function that take a threshold value, and analyze and plot our data\n",
    "def SST_above(thr):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2,figsize=(16,4))\n",
    "\n",
    "    # first part - values above threshold\n",
    "    sst.plot(ax=axs[0],linewidth=1)\n",
    "    sst.where(sst>=thr).plot.line('r.',markersize=3,ax=axs[0]) # test when data is equal or greater than the threshold. a is a logical array (True/False values)\n",
    "    axs[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # second part - days per year above threshold\n",
    "    hot = sst.where(sst>=thr,drop=True)\n",
    "    xr.plot.hist(hot.time.dt.year,ax=axs[1],bins=np.arange(2011.5,2020.5),rwidth=.8)\n",
    "    plt.ylabel('No. days above '+str(np.round(thr,1))+'C')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show() # display\n",
    "\n",
    "## Second, the actual analysis: two examples ##\n",
    "### Maximum climatology threshold\n",
    "thr = ds['+Std'].max().data # setting threshold as maximum climatological value: mean + 1 standard deviation\n",
    "print('Max climatological SST = ',np.round(thr,1),'C')\n",
    "SST_above(thr) # Call function we defined\n",
    "\n",
    "### A relevant threshold. \n",
    "# For example, for hawaii (the select region), 28C is a relevant threshold for coral bleaching (https://coralreefwatch.noaa.gov/product/5km/tutorial/crw08a_bleaching_threshold.php)\n",
    "thr = 28\n",
    "print('\\n\\nBiologically relevant SST = ',thr,'C')\n",
    "SST_above(thr) # Call function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Now, a different analsys of anomalously warm SST days. \n",
    "## Marine heatwaves\n",
    "Defined as any period with SST anomalies above the threshold set by the 90th percentile value of a given period SST anomalies - in this case our data time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate the threshold: 90th percentile\n",
    "thr = np.percentile(sst_anomaly, 90)\n",
    "\n",
    "fig, axs = plt.subplots(3,1,figsize=(16,16))\n",
    "\n",
    "# Same plot as in our function above, but this time we are plotting the anomalies.\n",
    "sst_anomaly.plot(ax=axs[0],linewidth=1)\n",
    "sst_anomaly.where(sst_anomaly>=thr).plot.line('r.',markersize=3,ax=axs[0]) # test when data is equal or greater than the threshold. a is a logical array (True/False values)\n",
    "axs[0].grid(True, alpha=0.3)\n",
    "axs[0].title.set_text('Location: '+str(latr)+'$^\\circ$N, '+str(lonr)+'$^\\circ$W')\n",
    "\n",
    "# Now plot on the original data (not anomalies)\n",
    "sst.plot(ax=axs[1],linewidth=1)\n",
    "sst.where(sst_anomaly>=thr).plot.line('r.',markersize=3,ax=axs[1]) # test when data is equal or greater than the threshold. a is a logical array (True/False values)\n",
    "axs[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot of marine heatwave days  per year\n",
    "hot = sst_anomaly.where(sst_anomaly>=thr,drop=True)\n",
    "xr.plot.hist(hot.time.dt.year,ax=axs[2],bins=np.arange(2011.5,2020.5),rwidth=.8)\n",
    "plt.ylabel('No. days SSTa > '+str(np.round(thr,1))+'C')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# print the numbers of days\n",
    "hot.groupby('time.year').count().data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Finally, let's explore the SST field around our selected point or region durring the warmest day or coldest day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out max and min SST values and the date when they occur\n",
    "minv = sst.min() # find mininum SST value\n",
    "mindate = sst[sst==minv].time.data # find when this min value occurred\n",
    "maxv = sst.max() # find maximum SST value\n",
    "maxdate = sst[sst==maxv].time.data # find when the max value occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that go back to the SST data in the cloud, but we now load a different subset \n",
    "# an specific day, but now always a region: the region selected or a region around the selected point\n",
    "def select_area(day):   # the function input is a day\n",
    "    if len(latr)==1: # if input data was one point\n",
    "        sst2 = ds_sst.sel(time = day, \n",
    "                            lat  = slice(latr-2,latr+2),\n",
    "                            lon  = slice(lonr-2,lonr+2)\n",
    "                            )\n",
    "    else: # if input data was a region\n",
    "        sst2 = ds_sst.sel(time = day,\n",
    "                            lat  = slice(latr[0], latr[1]), \n",
    "                            lon  = slice(lonr[0], lonr[1])\n",
    "                            )\n",
    "    sst3 = sst2['analysed_sst']-273.15\n",
    "    mask = sst2['mask'].where(sst2['mask']<2)\n",
    "    sst3 = sst3*mask\n",
    "    return sst3 # returns the data array of the region at the given date (the region is the defined at the beginning of the script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot warmest day\n",
    "msst = select_area(maxdate) # call function with day of warmest SST\n",
    "msst.hvplot.quadmesh(x='lon',y='lat',coastline=True, clabel='T [C]', cmap='coolwarm', title=str(maxdate[0])[:10])\n",
    "# this image plot also gives you extra information when you hover your cursor around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coolest day\n",
    "msst = select_area(mindate) # call function with day of coolest SST\n",
    "msst.hvplot.quadmesh(x='lon',y='lat',coastline=True, clabel='T [C]', cmap='coolwarm', title=str(mindate[0])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Resources\n",
    "\n",
    "For the cloud and data in the cloud, see resources listed in Chapter 5.\n",
    "\n",
    "Resources specifically for this chapter:\n",
    "- [MUR SST Data](https://registry.opendata.aws/mur/). SST data in the cloud, with references the official datta website, examples and other resources.\n",
    "- [Pangeo OSM2020 Tutorial](https://github.com/pangeo-gallery/osm2020tutorial). This is a very good tutorial for ocean application and cloud computing. Plenty of examples. Many of the commands here are from this tutorial.\n",
    "\n",
    "### About MHW\n",
    "\n",
    "- [Marine heatwaves](http://www.marineheatwaves.org/all-about-mhws.html). A good place to begin to get info about the subject.\n",
    "- [Marine heatwaves code](https://github.com/ecjoliver/marineHeatWaves). Marine heatwaves code from E. Oliver. \n",
    "\n",
    "### If you want to learn more:\n",
    "- [Methods for accessing a AWS bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-bucket-intro.html). Bucket is the name of the cloud storage object. S3 stands for Amazon's Simple Storage Service.\n",
    "- [hvplot site](https://hvplot.holoviz.org/index.html). Plotting tool used here.\n",
    "- [zarr](https://zarr.readthedocs.io/en/stable/) Big data storage formatt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
