{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import signal\n",
    "#import xesmf as xe\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get all the data at once, use same years for climatology for all data\n",
    "def get_data():\n",
    "    \n",
    "    #climatology years\n",
    "#    cyr1,cyr2='1993-01-01','2019-12-31'\n",
    "    cyr1,cyr2='2010-01-01','2019-12-31'\n",
    "    \n",
    "    # CCMP test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/ccmp/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds = ds.sortby(ds.lon)\n",
    "    ds = ds.sel(time=slice(cyr1,cyr2))\n",
    "    ds_ccmp = ds.drop('nobs')\n",
    "    # MAKE DAY AVERAGE\n",
    "    ds_ccmp = ds_ccmp.resample(time='D').mean()\n",
    "    for var in ds_ccmp:\n",
    "        tem = ds_ccmp[var].attrs\n",
    "        tem['var_name']='ccmp_'+str(var)\n",
    "        ds_ccmp[var].attrs=tem\n",
    "    ds_ccmp_clim = ds_ccmp.sel(time=slice(cyr1,cyr2))\n",
    "    ds_ccmp_clim = ds_ccmp_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    #sst\n",
    "    dir_pattern_zarr = 'F:/data/sst/cmc/zarr/'\n",
    "    ds_sst= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds_sst = ds_sst.drop({'analysis_error','mask','sea_ice_fraction'})\n",
    "    ds_sst = ds_sst.sel(time=slice(cyr1,cyr2))\n",
    "    tem = ds_sst.analysed_sst.attrs\n",
    "    tem['var_name']='cmc_sst'\n",
    "    ds_sst.analysed_sst.attrs=tem\n",
    "    ds_sst_clim = ds_sst.sel(time=slice(cyr1,cyr2))\n",
    "    ds_sst_clim = ds_sst_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    #put data into a dictionary\n",
    "    data_dict={'wnd':ds_ccmp,\n",
    "               'sst':ds_sst}\n",
    "    clim_dict={'wnd_clim':ds_ccmp_clim,\n",
    "               'sst_clim':ds_sst_clim}\n",
    "  \n",
    "    return data_dict,clim_dict\n",
    "\n",
    "\n",
    "def multi_apply_along_axis(func1d, axis, arrs, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    function from: https://climate-cms.org/2019/07/29/multi-apply-along-axis.html\n",
    "    Given a function `func1d(A, B, C, ..., *args, **kwargs)`  that acts on \n",
    "    multiple one dimensional arrays, apply that function to the N-dimensional\n",
    "    arrays listed by `arrs` along axis `axis`\n",
    "    \n",
    "    If `arrs` are one dimensional this is equivalent to::\n",
    "    \n",
    "        func1d(*arrs, *args, **kwargs)\n",
    "    \n",
    "    If there is only one array in `arrs` this is equivalent to::\n",
    "    \n",
    "        numpy.apply_along_axis(func1d, axis, arrs[0], *args, **kwargs)\n",
    "        \n",
    "    All arrays in `arrs` must have compatible dimensions to be able to run\n",
    "    `numpy.concatenate(arrs, axis)`\n",
    "    \n",
    "    Arguments:\n",
    "        func1d:   Function that operates on `len(arrs)` 1 dimensional arrays,\n",
    "                  with signature `f(*arrs, *args, **kwargs)`\n",
    "        axis:     Axis of all `arrs` to apply the function along\n",
    "        arrs:     Iterable of numpy arrays\n",
    "        *args:    Passed to func1d after array arguments\n",
    "        **kwargs: Passed to func1d as keyword arguments\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    # Concatenate the input arrays along the calculation axis to make one big\n",
    "    # array that can be passed in to `apply_along_axis`\n",
    "    carrs = numpy.concatenate(arrs, axis)\n",
    "    \n",
    "    # We'll need to split the concatenated arrays up before we apply `func1d`,\n",
    "    # here's the offsets to split them back into the originals\n",
    "    offsets=[]\n",
    "    start=0\n",
    "    for i in range(len(arrs)-1):\n",
    "        start += arrs[i].shape[axis]\n",
    "        offsets.append(start)\n",
    "            \n",
    "    # The helper closure splits up the concatenated array back into the components of `arrs`\n",
    "    # and then runs `func1d` on them\n",
    "    def helperfunc(a, *args, **kwargs):\n",
    "        arrs = numpy.split(a, offsets)\n",
    "        return func1d(*[*arrs, *args], **kwargs)\n",
    "    \n",
    "    # Run `apply_along_axis` along the concatenated array\n",
    "    return numpy.apply_along_axis(helperfunc, axis, carrs, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst, ds_wnd = data['sst'],data['wnd']\n",
    "ds_wnd['wspd']=(ds_wnd.uwnd**2+ds_wnd.vwnd**2)**.5\n",
    "#interp doesn't work on chunked dims so rechunk\n",
    "ds_sst = ds_sst.chunk({'time':1,'lat':901,'lon':1800})\n",
    "ds_new = ds_sst.interp(lat = ds_wnd.lat,lon=ds_wnd.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST\n",
    "#remove mean, seasonal cycle, trend before analysis\n",
    "clim = ds_new.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "ds_new_tem = ds_new.groupby('time.dayofyear')-clim\n",
    "#detrending doesn't work with nan so fill with nan but will have to mask at end and pixels with nan in timeseries\n",
    "tem = ds_new_tem.fillna(0)\n",
    "ds_detrended_sst = signal.detrend(tem.analysed_sst,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new_tem.analysed_sst.isel(lon=720,lat=310).plot()\n",
    "plt.plot(ds_new_tem.time,ds_detrended_sst[:,310,720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WSPD\n",
    "#remove mean, seasonal cycle, trend before analysis\n",
    "clim = ds_wnd.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "ds_new_tem = ds_wnd.groupby('time.dayofyear')-clim\n",
    "#detrending doesn't work with nan so fill with nan but will have to mask at end and pixels with nan in timeseries\n",
    "tem = ds_new_tem.fillna(0)\n",
    "ds_detrended_wnd = signal.detrend(tem.wspd,axis=0)\n",
    "ds_new_tem.wspd.isel(lon=720,lat=310).plot()\n",
    "plt.plot(ds_new_tem.time,ds_detrended_wnd[:,310,720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = multi_apply_along_axis(pearsonr, 0, [ds_detrended_sst,ds_detrended_wnd])\n",
    "print(corr.shape)\n",
    "print(type(corr))\n",
    "#not sure why by 1440 is blank\n",
    "acorr = corr[0,:,:]\n",
    "acorr2 = np.concatenate([acorr[:,720:1439],acorr[:,:1439],acorr[:,:720]],axis=1)\n",
    "#plt.imshow(acorr[:,:1439],vmin=-.1,vmax=.1,cmap='RdBu')\n",
    "#plt.imshow(acorr2,vmin=-.1,vmax=.1,cmap='viridis')\n",
    "data = acorr2\n",
    "data = np.nan_to_num(data,0)\n",
    "lowpass = ndimage.gaussian_filter(data, 40)\n",
    "gauss_highpass = data - lowpass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lowpass,vmin=-.1,vmax=.1,cmap='RdBu')\n",
    "plt.imshow(gauss_highpass,vmin=-.1,vmax=.1,cmap='RdBu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
